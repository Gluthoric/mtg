"""Remove import_record foreign key

Revision ID: c4c16fcaa592
Revises: 
Create Date: 2024-09-30 17:03:51.373292

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'c4c16fcaa592'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.execute("CREATE TABLE IF NOT EXISTS set_collection_counts ("
               "set_code TEXT NOT NULL, "
               "collection_count INTEGER NOT NULL, "
               "PRIMARY KEY (set_code), "
               "FOREIGN KEY(set_code) REFERENCES sets (code) ON DELETE CASCADE"
               ")")
    
    # Remove foreign key constraint and drop column from cards table
    with op.batch_alter_table('cards', schema=None) as batch_op:
        batch_op.drop_constraint('cards_import_record_id_fkey', type_='foreignkey')
        batch_op.drop_index('ix_cards_import_record_id')
        batch_op.drop_column('import_record_id')
        batch_op.alter_column('oracle_id',
               existing_type=sa.TEXT(),
               nullable=True)
        batch_op.alter_column('set_code',
               existing_type=sa.TEXT(),
               nullable=True)

    # Now we can safely drop the import_records table
    op.drop_table('import_records')

    # Modify the sets table
    with op.batch_alter_table('sets', schema=None) as batch_op:
        # Create a new unique constraint on 'id' before dropping the old one
        batch_op.create_unique_constraint('sets_id_key', ['id'])

    # Drop the foreign key constraint on cards table
    op.drop_constraint('cards_set_code_fkey', 'cards', type_='foreignkey')

    # Now we can safely drop the unique constraint on sets.code
    with op.batch_alter_table('sets', schema=None) as batch_op:
        batch_op.drop_constraint('sets_code_key', type_='unique')

    # Recreate the foreign key constraint
    op.create_foreign_key('cards_set_code_fkey', 'cards', 'sets', ['set_code'], ['code'])

    # ### end Alembic commands ###


def downgrade():
    # Recreate the import_records table
    op.create_table('import_records',
    sa.Column('id', sa.VARCHAR(length=36), autoincrement=False, nullable=False),
    sa.Column('timestamp', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('summary', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='import_records_pkey')
    )

    # Add the import_record_id column back to the cards table
    with op.batch_alter_table('cards', schema=None) as batch_op:
        batch_op.add_column(sa.Column('import_record_id', sa.VARCHAR(length=36), autoincrement=False, nullable=True))
        batch_op.create_foreign_key('cards_import_record_id_fkey', 'import_records', ['import_record_id'], ['id'])
        batch_op.create_index('ix_cards_import_record_id', ['import_record_id'], unique=False)
        
        # Update null set_code values to an empty string before setting NOT NULL
        op.execute("UPDATE cards SET set_code = '' WHERE set_code IS NULL")
        batch_op.alter_column('set_code', existing_type=sa.TEXT(), nullable=False)
        
        # Update null oracle_id values to an empty string before setting NOT NULL
        op.execute("UPDATE cards SET oracle_id = '' WHERE oracle_id IS NULL")
        batch_op.alter_column('oracle_id', existing_type=sa.TEXT(), nullable=False)

    # Revert changes to the sets table
    with op.batch_alter_table('sets', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='unique')
        batch_op.create_unique_constraint('sets_code_key', ['code'])

    # Drop the set_collection_counts table
    op.drop_table('set_collection_counts')
